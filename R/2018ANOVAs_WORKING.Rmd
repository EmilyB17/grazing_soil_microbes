---
title: "2018 Data Analysis - Univariate"
author: "Emily Bean"
date: "September 25, 2018"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

### Overview  
##### Author: Emily Bean  
##### Author contact: ebean@uwyo.edu  

```{r, include = FALSE, message = FALSE, warning = FALSE}
## All packages required & sourced data
if(!require(prettydoc)) install.packages("prettydoc")
library(prettydoc)
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
if(!require(lme4)) install.packages("lme4")
library(lme4)
if(!require(MuMIn)) install.packages("MuMIn")
library(MuMIn)
prepDataGLM17 <- function(data) {
  data$SampDate <- NULL
  data$Plot <- NULL
  data$Block <- factor(data$Block)
  data$Treatment <- as.factor(data$Treatment)
  data$GrazeTime <- factor(data$GrazeTime)
  data$Sample <- NULL
  return(data)
}
prepDataGLM18 <- function(data) {
  data$Plot <- NULL
  data$Block <- factor(data$Block)
  data$Treatment <- as.factor(data$Treatment)
  data$GrazeTime <- factor(data$GrazeTime)
  return(data)
}
# test change for commit issues
## Read in data
cn <- prepDataGLM18(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2018CN_data_updated10_18.txt", header = TRUE))

enz <- prepDataGLM18(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2018enzymes_vertical.txt", header = TRUE))

veg <- prepDataGLM18(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2018rpm.txt", header = TRUE))

cn17 <- prepDataGLM17(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2017CN_data_updated10_18.txt", sep = "\t", header = TRUE))

mbc17 <- cn17[complete.cases(cn17),] # removes rows with NA values for MBC & MBN

cn17 <- cn17[, -(9:10)] # removes MBC and MBN columns so NAs don't mess up GLMs

grav17 <- prepDataGLM17(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2017Gravimetric_moisture.txt", sep = "\t", header = TRUE))

enz17 <- prepDataGLM17(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2017enzymes_vertical.txt", sep = "\t", header = TRUE))

ph17 <- prepDataGLM17(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/2017pH.txt", sep = "\t", header = TRUE))

rpm17 <- prepDataGLM17(read.table("https://raw.githubusercontent.com/EmilyB17/grazing_soil_microbes/master/data/rpm_Plot48.txt", sep = "\t", header = TRUE))
rpm17$biomass_kg_plot <- (82.322 * rpm17$Reading) - 341.742
rpm17[,(4:7)] <- NULL

# create microbial efficiency calculation
eff17 <- merge(mbc17, enz17, by = c("Block", "Treatment", "GrazeTime"))
eff17$efficiency <- eff17$Enzyme_nm_g_hr / eff17$MBC_mgkgdrysoil
eff17$efficiency[eff17$efficiency %in% "Inf"] <- 0
eff17$efficiency[eff17$efficiency %in% "NaN"] <- 0
eff17$Enzyme_nm_g_hr <- NULL
#eff17$efficiency[eff17$efficiency < 0] <- 0

## Forage Utlization (how much did the cattle eat of the available forage?)
# HI: PRE - 24H / PRE (24H after HI grazing)
for.hi <- data.frame(((veg$biomass_kg_plot[veg$Treatment %in% "HI" & veg$GrazeTime %in% "PRE"] -
                         veg$biomass_kg_plot[veg$Treatment %in% "HI" & veg$GrazeTime %in% "24H"]) /
                        veg$biomass_kg_plot[veg$Treatment %in% "HI" & veg$GrazeTime %in% "PRE"]) * 100)
for.hi$Treatment <- "HI"
colnames(for.hi) <- c("forage_ut", "Treatment")
# LO: PRE - 1WK / PRE (24H after LO grazing)
for.lo <- data.frame(((veg$biomass_kg_plot[veg$Treatment %in% "LO" & veg$GrazeTime %in% "PRE"] -
                         veg$biomass_kg_plot[veg$Treatment %in% "LO" & veg$GrazeTime %in% "1WK"]) /
                        veg$biomass_kg_plot[veg$Treatment %in% "LO" & veg$GrazeTime %in% "PRE"]) * 100)
for.lo$Treatment <- "LO"
colnames(for.lo) <- c("forage_ut", "Treatment")
# combine into one dataframe for comparisons
for.ut18 <- rbind(for.hi, for.lo)

## 2017
## Forage Utlization (how much did the cattle eat of the available forage?)
# HI: PRE - 24H / PRE (24H after HI grazing)
for.hi <- data.frame(((rpm17$biomass_kg_plot[rpm17$Treatment %in% "HI" & rpm17$GrazeTime %in% "PRE"] -
                         rpm17$biomass_kg_plot[rpm17$Treatment %in% "HI" & rpm17$GrazeTime %in% "24H"]) /
                        rpm17$biomass_kg_plot[rpm17$Treatment %in% "HI" & rpm17$GrazeTime %in% "PRE"]) * 100)
for.hi$Treatment <- "HI"
colnames(for.hi) <- c("forage_ut", "Treatment")
# LO: PRE - 1WK / PRE (24H after LO grazing)
for.lo <- data.frame(((rpm17$biomass_kg_plot[rpm17$Treatment %in% "LO" & rpm17$GrazeTime %in% "PRE"] -
                         rpm17$biomass_kg_plot[rpm17$Treatment %in% "LO" & rpm17$GrazeTime %in% "1WK"]) /
                        rpm17$biomass_kg_plot[rpm17$Treatment %in% "LO" & rpm17$GrazeTime %in% "PRE"]) * 100)
for.lo$Treatment <- "LO"
colnames(for.lo) <- c("forage_ut", "Treatment")
# combine into one dataframe for comparisons
for.ut17 <- rbind(for.hi, for.lo)

## 2018
## Vegetation Recovery Per Day (how much the forage grew back based on days after grazing to final sampling)
# HI: 28 recovery days
# LO: 22 recovery days
# NO: 35 recovery days (all days of the grazing trial from PRE to 4WK)

# calculate vegetation recovery
hi.rec <- data.frame((veg$biomass_kg_plot[veg$Treatment %in% "HI" & veg$GrazeTime %in% "4WK"] -
                        veg$biomass_kg_plot[veg$Treatment %in% "HI" & veg$GrazeTime %in% "24H"]) / 28)
colnames(hi.rec) <- "veg_rec"
hi.rec$Treatment <- "HI"
lo.rec <- data.frame((veg$biomass_kg_plot[veg$Treatment %in% "LO" & veg$GrazeTime %in% "4WK"] -
                        veg$biomass_kg_plot[veg$Treatment %in% "LO" & veg$GrazeTime %in% "1WK"]) / 22)
colnames(lo.rec) <- "veg_rec"
lo.rec$Treatment <- "LO"
no.rec <- data.frame((veg$biomass_kg_plot[veg$Treatment %in% "NO" & veg$GrazeTime %in% "4WK"] -
                        veg$biomass_kg_plot[veg$Treatment %in% "NO" & veg$GrazeTime %in% "PRE"]) / 35)
colnames(no.rec) <- "veg_rec"
no.rec$Treatment <- "NO"
# create data frame
veg.rec18 <- rbind(hi.rec, lo.rec, no.rec)
veg.rec18$Treatment <- as.factor(veg.rec18$Treatment)

## 2017
## Vegetation Recovery
# HI: 22 days recovery
# LO: 20 days recovery
# NO: 35 days recovery
# calculate vegetation recovery
hi.rec <- data.frame((rpm17$biomass_kg_plot[rpm17$Treatment %in% "HI" & rpm17$GrazeTime %in% "4WK"] -
                        rpm17$biomass_kg_plot[rpm17$Treatment %in% "HI" & rpm17$GrazeTime %in% "24H"]) / 22)
colnames(hi.rec) <- "veg_rec"
hi.rec$Treatment <- "HI"
lo.rec <- data.frame((rpm17$biomass_kg_plot[rpm17$Treatment %in% "LO" & rpm17$GrazeTime %in% "4WK"] -
                        rpm17$biomass_kg_plot[rpm17$Treatment %in% "LO" & rpm17$GrazeTime %in% "1WK"]) / 20)
colnames(lo.rec) <- "veg_rec"
lo.rec$Treatment <- "LO"
no.rec <- data.frame((rpm17$biomass_kg_plot[rpm17$Treatment %in% "NO" & rpm17$GrazeTime %in% "4WK"] -
                        rpm17$biomass_kg_plot[rpm17$Treatment %in% "NO" & rpm17$GrazeTime %in% "PRE"]) / 35)
colnames(no.rec) <- "veg_rec"
no.rec$Treatment <- "NO"
# create data frame
veg.rec17 <- rbind(hi.rec, lo.rec, no.rec)
veg.rec17$Treatment <- as.factor(veg.rec17$Treatment)

## Functions to perform uniform data analysis on all variables
# First function performs step 1 through 3
# where "data" is a dataframe and "variable.name" is a character string of the response variable
step1to3 <- function(data, variable.name) {
  f <- as.formula(paste(variable.name, "~", " Treatment * GrazeTime", sep = ""))
  # create model object
  mod <- lm(f, data = data)
  # check for influential data points
  sum <- summary(influence.measures(mod))
  
  # delineate graphical parameters
  op <- par(mfrow = c(3,2), mar = c(5, 4, 1, 2))    
  # boxplot to look for outliers
  p <- boxplot(f, data = data, main = "Boxplot for Outliers")
  
  # create standard model validation graphs
  # plot 1: residuals vs. fitted values (test homogeneity)
  p1 <- plot(lm(f, data = data), add.smooth = FALSE, which = 1)
  # plot 2: QQ plot (test normality)
  p2 <- qqnorm(resid(mod))
  p3 <- qqline(resid(mod))
  # plot 3: residuals vs each explanatory variable (test independence)
  p4 <- plot(data$GrazeTime, 
             resid(mod), xlab = "GrazeTime", ylab = "Residuals", 
             main = "Residuals vs. explan. var.")
  p5 <- plot(data$Treatment, resid(mod), xlab = "Treatment", ylab = "Residuals",
             main = "Residuals vs. explan. var.")
  
  return(list(sum, p, p1, p2, p3, p4))
  #return(p1, p2, p3, p4)
}


# function to perform steps 4 through 5 of data analysis
# arguments: data is a dataframe
# variable.name is a character string of the response variable
step4to5 <- function(data, variable.name) {
  # perform dredge function to find the best fitting model parameters
  # Gamma distribution
  # make the Gamma distribution happy by replacing zeros with small number
  dataf <- data
  dataf$newcol <- ifelse(dataf[,variable.name] == 0, 0.0001, dataf[, variable.name])
  dataf[, variable.name] <- NULL
  f<- as.formula(paste("newcol", " ~ Treatment * GrazeTime", sep = ""))
  modsGamma <- get.models(dredge(
    glm(f,
        family = Gamma(link = "log"), data = dataf, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f1 <- as.formula(paste("newcol", " ~ .", sep = ""))
  modsGamma1 <- get.models(dredge(
    glm(f1,
        family = Gamma(link = "log"), data = dataf, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian distribution
  f2 <- as.formula(paste(variable.name, " ~ Treatment * GrazeTime", sep = ""))
  modsGaussian <- get.models(dredge(
    glm(f2,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f3 <- as.formula(paste(variable.name, " ~ .", sep = ""))
  modsGaussian1 <- get.models(dredge(
    glm(f3,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian with a log distribution
  f4 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ Treatment * GrazeTime", sep = ""))
  modsGaussianLog <- get.models(dredge(
    glm(f4,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f5 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ .", sep = ""))
  modsGaussianLog1 <- get.models(dredge(
    glm(f5,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # summarize the 3 models in one list
  combine <- list(modsGamma, modsGamma1, modsGaussian, modsGaussian1,
                  modsGaussianLog, modsGaussianLog1)
  names(combine) <- c("Gamma TrtGrz", "Gamma All", "Gaussian TrtGrz", 
                      "Gaussian All","Gaussian Log TrtGrz", "Gaussian Log All")
  
  # print QQPlots for the 3 models to determine which is the best fit
  op <- par(mfrow = c(2, 3))
  qqnorm(resid(modsGamma[[1]]), main = "Gamma TrtGrz QQPlot")
  qqline(resid(modsGamma[[1]]))
  qqnorm(resid(modsGamma1[[1]]), main = "Gamma All  QQPlot")
  qqline(resid(modsGamma1[[1]]))
  qqnorm(resid(modsGaussian[[1]]), main = "Gaussian TrtGrz QQPlot")
  qqline(resid(modsGaussian[[1]]))
  qqnorm(resid(modsGaussian1[[1]]), main = "Gaussian All QQPlot")
  qqline(resid(modsGaussian1[[1]]))
  qqnorm(resid(modsGaussianLog[[1]]), main = "GaussianLog TrtGrz QQPlot")
  qqline(resid(modsGaussianLog[[1]]))
  qqnorm(resid(modsGaussianLog1[[1]]), main = "GaussianLog All QQPlot")
  qqline(resid(modsGaussianLog1[[1]]))
  # return the list of model summaries
  return(combine)
}


# This function removes the Gamma distribution for datasets that are too zero-inflated 
step4to5zeroinfl <- function(data, variable.name) {
  # perform dredge function to find the best fitting model parameters
  # Gaussian distribution
  # Gaussian distribution
  f2 <- as.formula(paste(variable.name, " ~ Treatment * GrazeTime", sep = ""))
  modsGaussian <- get.models(dredge(
    glm(f2,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f3 <- as.formula(paste(variable.name, " ~ .", sep = ""))
  modsGaussian1 <- get.models(dredge(
    glm(f3,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian with a log distribution
  f4 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ Treatment * GrazeTime", sep = ""))
  modsGaussianLog <- get.models(dredge(
    glm(f4,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f5 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ .", sep = ""))
  modsGaussianLog1 <- get.models(dredge(
    glm(f5,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # summarize the 3 models in one list
  combine <- list(modsGaussian, modsGaussian1,
                  modsGaussianLog, modsGaussianLog1)
  names(combine) <- c("Gaussian TrtGrz", 
                      "Gaussian All","Gaussian Log TrtGrz", "Gaussian Log All")
  
  # print QQPlots for the 3 models to determine which is the best fit
  op <- par(mfrow = c(2, 2))
  qqnorm(resid(modsGaussian[[1]]), main = "Gaussian TrtGrz QQPlot")
  qqline(resid(modsGaussian[[1]]))
  qqnorm(resid(modsGaussian1[[1]]), main = "Gaussian All QQPlot")
  qqline(resid(modsGaussian1[[1]]))
  qqnorm(resid(modsGaussianLog[[1]]), main = "GaussianLog TrtGrz QQPlot")
  qqline(resid(modsGaussianLog[[1]]))
  qqnorm(resid(modsGaussianLog1[[1]]), main = "GaussianLog All QQPlot")
  qqline(resid(modsGaussianLog1[[1]]))
  # return the list of model summaries
  return(combine)
}

# This function removes the Substrate column from the dataframe for enzyme assays
step4to5enz <- function(data, variable.name) {
  # perform dredge function to find the best fitting model parameters
  data$Substrate <- NULL
  # Gamma distribution
  # make the Gamma distribution happy by replacing zeros with small number
  dataf <- data
  dataf$newcol <- ifelse(dataf[,variable.name] == 0, 0.0001, dataf[, variable.name])
  dataf[, variable.name] <- NULL
  f<- as.formula(paste("newcol", " ~ Treatment * GrazeTime", sep = ""))
  modsGamma <- get.models(dredge(
    glm(f,
        family = Gamma(link = "log"), data = dataf, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f1 <- as.formula(paste("newcol", " ~ .", sep = ""))
  modsGamma1 <- get.models(dredge(
    glm(f1,
        family = Gamma(link = "log"), data = dataf, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian distribution
  f2 <- as.formula(paste(variable.name, " ~ Treatment * GrazeTime", sep = ""))
  modsGaussian <- get.models(dredge(
    glm(f2,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f3 <- as.formula(paste(variable.name, " ~ .", sep = ""))
  modsGaussian1 <- get.models(dredge(
    glm(f3,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian with a log distribution
  f4 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ Treatment * GrazeTime", sep = ""))
  modsGaussianLog <- get.models(dredge(
    glm(f4,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f5 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ .", sep = ""))
  modsGaussianLog1 <- get.models(dredge(
    glm(f5,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # summarize the 3 models in one list
  combine <- list(modsGamma, modsGamma1, modsGaussian, modsGaussian1,
                  modsGaussianLog, modsGaussianLog1)
  names(combine) <- c("Gamma TrtGrz", "Gamma All", "Gaussian TrtGrz", 
                      "Gaussian All","Gaussian Log TrtGrz", "Gaussian Log All")
  
  # print QQPlots for the 3 models to determine which is the best fit
  op <- par(mfrow = c(2, 3))
  qqnorm(resid(modsGamma[[1]]), main = "Gamma TrtGrz QQPlot")
  qqline(resid(modsGamma[[1]]))
  qqnorm(resid(modsGamma1[[1]]), main = "Gamma All  QQPlot")
  qqline(resid(modsGamma1[[1]]))
  qqnorm(resid(modsGaussian[[1]]), main = "Gaussian TrtGrz QQPlot")
  qqline(resid(modsGaussian[[1]]))
  qqnorm(resid(modsGaussian1[[1]]), main = "Gaussian All QQPlot")
  qqline(resid(modsGaussian1[[1]]))
  qqnorm(resid(modsGaussianLog[[1]]), main = "GaussianLog TrtGrz QQPlot")
  qqline(resid(modsGaussianLog[[1]]))
  qqnorm(resid(modsGaussianLog1[[1]]), main = "GaussianLog All QQPlot")
  qqline(resid(modsGaussianLog1[[1]]))
  # return the list of model summaries
  return(combine)
}

step4to5enz_zeroinfl <- function(data, variable.name) {
  # perform dredge function to find the best fitting model parameters
  data$Substrate <- NULL
  # Gaussian distribution
  f2 <- as.formula(paste(variable.name, " ~ Treatment * GrazeTime", sep = ""))
  modsGaussian <- get.models(dredge(
    glm(f2,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f3 <- as.formula(paste(variable.name, " ~ .", sep = ""))
  modsGaussian1 <- get.models(dredge(
    glm(f3,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # Gaussian with a log distribution
  f4 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ Treatment * GrazeTime", sep = ""))
  modsGaussianLog <- get.models(dredge(
    glm(f4,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  f5 <- as.formula(paste( "log1p(", variable.name, ")",  " ~ .", sep = ""))
  modsGaussianLog1 <- get.models(dredge(
    glm(f5,
        data = data, na.action = "na.fail")),
    subset = cumsum(weight) <= 0.95)[1]
  # summarize the 3 models in one list
  combine <- list(modsGaussian, modsGaussian1,
                  modsGaussianLog, modsGaussianLog1)
  names(combine) <- c("Gaussian TrtGrz", 
                      "Gaussian All","Gaussian Log TrtGrz", "Gaussian Log All")
  
  # print QQPlots for the 3 models to determine which is the best fit
  op <- par(mfrow = c(2, 2))
  qqnorm(resid(modsGaussian[[1]]), main = "Gaussian TrtGrz QQPlot")
  qqline(resid(modsGaussian[[1]]))
  qqnorm(resid(modsGaussian1[[1]]), main = "Gaussian All QQPlot")
  qqline(resid(modsGaussian1[[1]]))
  qqnorm(resid(modsGaussianLog[[1]]), main = "GaussianLog TrtGrz QQPlot")
  qqline(resid(modsGaussianLog[[1]]))
  qqnorm(resid(modsGaussianLog1[[1]]), main = "GaussianLog All QQPlot")
  qqline(resid(modsGaussianLog1[[1]]))
  # return the list of model summaries
  return(combine)
}


step6 <- function(bestModel) { # best Model is the call , make sure to replace data with the dataframe
  s <- summary(bestModel[[1]])
  c <- data.frame(variable = row.names(confint(bestModel, level = 0.95)),
                     CI_2.5 = confint(bestModel, level = 0.95)[,1],
                     CI_97.5 = confint(bestModel, level = 0.95)[,2])
  p <- ggplot(data = c) +
    geom_point(aes(x = variable, y = CI_2.5, color = "red")) +
    geom_point(aes(x = variable, y = CI_97.5, color = "blue")) +
    labs(x = "Variable Name", y = "Confidence Intervals", title = "Model Significance")
  return(p)
}


```

The purpose of this document is to hold the statistical analyses and write-ups with explanations and results in one place. Finalized code will be as concise as possible.  

### Statistical Design: Univariate Analyses  

Univariate analyses will be organized by subject, starting with 2018 data, then 2017 data (including bulk density, microbial biomass C, microbial efficiency where there is only data for 2017), then 2018 and 2017 data combined.  

*Steps for each analysis*  
1. Use graphical exploratory data analysis (Gotelli and Ellison 2013). Plot the data to look for statistical outliers: use a boxplot where whiskers extend to 1.58% of the inter-quartile range.  
2. Check for influential data points with influence.measures() function. Potential influential measures violate the assumptions of linear regression.
3. Fit a linear regression model and test the assumptions of (1) homogeneity, (2) normality, and (3) independence. Following the methods of XXX, the statistical model validations will be done visually by inspecting: a residuals versus fitted values plot (checks homogeneity), a QQ plot (checks normality), and a residuals versus each explanatory variable (checks independence). 
4. If the linear assumptions are met, run a basic generalized linear model with a Gaussian (normal) distribution and look for significance. Use a log transformation if it improves the model's AIC.
4. If the assumptions of the linear regression are violated (as in the case of most of these datasets), fit a Gamma distribution with a log link and use the dredge() function to select the parameters with the lowest AIC. The Gamma distribution is used for positive continuous data that violates normality. The dredge() function will specify covariates, and we will use a log link as it is the most common and the easiest to back-transform.
5. Examine the residuals of the best fitting model in a QQplot.
6. When a best-fitting model is chosen, examine the confidence intervals and determine if confident intervals between explanatory variables overlap. If the CIs do not overlap, the variables are considered statistically significant from each other.
  
### 2018 Data
#### Gravimetric Moisture  

Gravimetric moisture was measured by drying and weighing the soil at 105C for 24 hours. The boxplot does not indicate any statistical outliers. There are appear to be two data points that are potentially influential. The plots that validate the assumptions of linear regression clearly display that almost all assumptions are violated: the residuals vs. fitted plot shows a lopsided spread of residuals, the QQ-plot shows non-normality, and there is a heteroscedastic spread of residuals for the explanatory variable GrazeTime. Clearly, linear regression is not the way to go for this variable.
The dredge function shows that the log-transformed Gaussian distribution has the lowest AIC by over 100 units. That model determines that GrazeTime and nitrate are the best fitting explanatory variables. The plotted confidence intervals indicate that the intercept (1WK GrazeTime) is significant from the other GrazeTimes, and nitrate is also significant from the other variables.

This data analysis indicates that GrazeTime and nitrate are the best explanatory variables for gravimetric moisture. There is a significantly high spike in soil moisture at the 1WK time point, which is likely attributed to a rain event and seasonal fluxes. Nitrate is correlated to gravimetric moisture, so there are biogeochemical drivers at work which warrant further inspection.

```{r,knitr::opts_chunk$set(include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE)}
x <- step1to3(data = cn, variable.name = "grav_mois")
y <- step4to5(data = cn, variable.name = "grav_mois")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log(grav_mois) ~ GrazeTime + NO3_mgkgdrysoil + 
    1, data = cn, na.action = "na.fail"))
z
```


#### Dissolved Organic Carbon (non-purgeable organic carbon)  

Non-purgeable organic carbon (NPOC) is analyzed in the same way as dissolved organic carbon, except the carbonates are burnt off before analysis. This is the preferred method for soils that have a high pH and large amounts of inorganic carbon. Briefly, a 10g subsample of soil was extracted in 50mL 0.5M K~2~SO~4~ and filtered throuh Q50 Whatman filters. The extracts were analyzed for NPOC and DON via combustion catalytic oxidation/NDIR method (Shimadzu TOC-VCPH with TNM-1, Shimadzu Corporation).
There is one influential measure, and the linear regression assumptions are met except for the fitted residuals, which show vertical patterns. The best fitting model based on AIC is the log-tranformed Gaussian distribution, which shows that the explanatory variables are Block, dissolved organic nitrogen, GrazeTime, and Treatment. However, examination of the confidence intervals shows a strong significance at Block 1, and the other variables don't seem significant to each other. The LO and NO treatment are significant from the Block and GrazeTime variables.

This dataset shows that there is a strong block effect for the distribution of soil carbon, as well as an effect with GrazeTime and with Treatment. 
```{r, include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE}
x <- step1to3(data = cn, variable.name = "NPOC_mgkgdrysoil")
y <- step4to5(data = cn, variable.name = "NPOC_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log(NPOC_mgkgdrysoil) ~ Block + DON_mgkgdrysoil + 
    GrazeTime + Treatment + 1, data = cn, na.action = "na.fail"))
z
```


#### Dissolved Organic Nitrogen

Total organic N was analyzed via combustion catalytic oxidation/NDIR method (see NPOC above). DON was calculated by subtracting mineral N from total organic N. There are four potentially influential observations, and the other statistical model validation plots show a slight violation of normality but all other assumptions are met.
Interestingly, the three model tests show that while the GaussianLog distribution has the lowest AIC, the QQPlots show that the Gaussian QQPlot shows the best distribution of normality. Not surprisingly, the model shows that DON is best explained by mineral N and NPOC. Therefore, significance is not important. However, the final plot shows that mineral N and NPOC both have very small confidence intervals and are significant to each other and to the intercept.

The general trend shown by the biogeochemical data is that they are more related to each other than any other variable, including GrazeTime and Treatment. This suggests that there might be a better way to examine the data relative to GrazeTime or Treatment than a GLM. 

```{r, include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE}
x <- step1to3(data = cn, variable.name = "DON_mgkgdrysoil")
y <- step4to5(data = cn, variable.name = "DON_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(DON_mgkgdrysoil) ~ mineralN_mgkgdrysoil + 
                             NPOC_mgkgdrysoil + 1, data = cn, na.action = "na.fail"))
z

```




#### Nitrate-N

Nitrate-N was analyzed by extraction with 0.5M K~2~SO~4~ (Doane and Horwatch, 2003). Initial diagnostic plots indicate several problems. There are multiple outliers, but the outliers are spread through the GrazeTime, indicating that they are likely true outliers and not laboratory errors. There are multiple influential observations, and the linear regression plots show that the spread of residuals is uneven and the data is not normal. 

This data is so heavily zero-inflated that the Gamma log-linked distribution doesn't run properly, so we will only examine the Gaussian and log-transformed Gaussian distributions. The model selections show that a log transformation significantly improves the data, and the best selected variables are DON, mineral N, NH4, and NPOC. The confidence interval plot shows that these biogeochemical parameters are all significant to each other 

```{r, include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE}
x <- step1to3(data = cn, variable.name = "NO3_mgkgdrysoil")
y <- step4to5zeroinfl(data = cn, variable.name = "NO3_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(NO3_mgkgdrysoil) ~ DON_mgkgdrysoil + mineralN_mgkgdrysoil + 
                             NH4_mgkgdrysoil + NPOC_mgkgdrysoil + 1, data = cn, na.action = "na.fail"))
z
```



#### Ammonium-N

The boxplot shows one extreme outlier. The analysis was repeated and the outlier remained extreme, so it is likely not a lab mistake. Therefore, this analysis will be performed with and without the outlier, to explore its true influence. After the outlier is removed, the data fits a linear regression model much better. However, removing this datapoint could be ignorant and problematic, as it could represent a true soil condition (for example, increased labile N from cattle urine). It could also represent an abnormality in spatial heterogeneity (for example, a sample from a patch of soil that was recently urinated on by a cow). Unfortunately, without knowing for sure I am hesitant to just get rid of the point.

The Gaussian distribution fit so badly that the entire function failed, so I ran this by hand and found that the log-distributed Gaussian fit the best, and that the best explanatory variables were all of the biogeochemical variables. These all have narrow confidenve intervals compared to the intercept, and are significant to each other.

```{r, include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE}
x <- step1to3(data = cn, variable.name = "NH4_mgkgdrysoil")
#y <- step4to5(data = cn, variable.name = "NH4_mgkgdrysoil")
#y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(NH4_mgkgdrysoil) ~ grav_mois + mineralN_mgkgdrysoil + 
                             NO3_mgkgdrysoil + NPOC_mgkgdrysoil + 1, data = cn, na.action = "na.fail"))
z
```


#### Mineral-N

Mineral Nitrogen is the addition of nitrate-N and ammonium-N (then subtracting dissolved organic N), and represents the pool of the most plant-available N in the soil. The initial data exploration shows that the data is widely distributed, and does not fit any assumption of linear regressions. Additionally, there are 6 potentially influential observations, which suggests that this data is widely skewed by multiple outliers.
Since this dataset is a combination of nitrate and ammonium, it shows characteristics of both. Therefore, the Gaussian distribution fits terribly, and the best fit model is the log-transformed Gaussian. The best model parameters are all of the biogeochemical factors. Interestingly, all of the biogeochemical parameters are significant to the intercept.

```{r, include = TRUE, collapse = TRUE, echo = FALSE, error = FALSE, warning = FALSE}
x <- step1to3(data = cn, variable.name = "mineralN_mgkgdrysoil")
y <- step4to5(data = cn, variable.name = "mineralN_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(mineralN_mgkgdrysoil) ~ DON_mgkgdrysoil + 
                             grav_mois + NH4_mgkgdrysoil + NO3_mgkgdrysoil + NPOC_mgkgdrysoil + 
                             1, data = cn, na.action = "na.fail"))
z
```


#### Extracellular enzyme assays  

Extracellular enzymes are secreted by soil microbes to degrade organic matter. This critical part of the soil nutrient cycle is commonly analyzed as a proxy to soil microbial activity, and can also be used to speculate at nutrient availability, as extracellular enzymes are secreted based on cellular economics. Enzyme assays are either fluorometric (hydrolytic enyzmes) or colorimetric (oxidative enzymes). Fluorometric analyses follow (Bell et al 2013) while colorimetric enzymes follow (Saiya-Cork et al 2002).  
Each substrate represents a different type or complexity of organic matter that might be present in the soil, so it is imperative that they are analyzed separately. The entire enzymatic profile can also be considered, but here we will consider each substrate independently of the others. While this creates a lot of code, it is worth digging into each substrate's individual profile.

**It is likely that these datasets are too zero-inflated to fit a Gamma or Gaussian distribution, and the proper way to do this would be to incorporate a zero-inflated negative binomial. However, since GLMs for most substrates suggest that Treatment is a significant factor, this could be worth figuring out.**


```{r}
# step 1: look for outliers with a boxplot
ggplot(data = enz, aes(x = GrazeTime, y = Enzyme_nm_g_hr, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Enzymes 2018 Outliers") +
  labs(x = "GrazeTime", y = "Enzyme activity nm/g soil/hr") +
  facet_wrap(~ Substrate)

# step 2: look for influential data points
sub <- unique(enz$Substrate)
infl <- list()
for(i in 1:length(sub)) {
  infl <- c(infl, list(influence.measures(
    lm(Enzyme_nm_g_hr ~ Treatment * GrazeTime, data = filter(enz, Substrate == sub[i])))))
}
names(infl) <- sub
lapply(infl, summary)
```
##### AG

Alpha-glucosidase, or AG, hydrolyzes starch. AG is considered a "simple" carbon substrate, and can represent the functional ability of soil microbes to degrade simple carbon complexes. This dataset shows a few low outliers that skew normality, and an uneven spread of residuals vs. explanatory variables. The QQplot shows that the data is not normally distributed.


```{r}
x <- step1to3(data = enz[enz$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz[enz$Substrate %in% "AG",], 
                           na.action = "na.fail"))
z
```

##### BG

Beta-glucosidase, or BG, is one of the most commonly measured extracellular enzymes. BG hydrolyzes cellobiose to glucose, representing a fundamental and critical step in organic matter degradation. BG also represents a simple carbon complex. 

The BG data initial data exploration shows that similar to AG, there are outliers that are skewing normality. In further model selection, there is still no QQPlot that shows normality assumptions are met. The model with the lowest AIC is the log-transformed Gaussian, which shows that Block and Treatment are important explanatory variables. 
```{r}
x <- step1to3(data = enz[enz$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, 
                           data = enz[enz$Substrate %in% "BG",], na.action = "na.fail"))
z
```

##### BX  

Beta-xylosidase, or BX, performs one step of hemicellulose degradation. BX is considered a moderately complex substrate. 

This dataset looks similar to AG and BG and shares the same problem of not being pursuaded to normality well, and Block and Treatment are the best explanatory variables in the log-transformed Gaussian distribution. 

```{r}
x <- step1to3(data = enz[enz$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, 
                           data = enz[enz$Substrate %in% "BX",], na.action = "na.fail"))
z

```


##### CBH  

Cellobiohydrolase, or CBH, acts in cellulose degradation. Cellulose is a more complex carbon substrate. 

This data shows the same trends as BG and BX.


```{r}
x <- step1to3(data = enz[enz$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz[enz$Substrate %in% "CBH",], 
                           na.action = "na.fail"))
z

```

##### LAP  

Leucine aminopeptidase, or LAP, degrades polypeptides. LAP is involved in nitrogen cycling, so is used as a proxy for functional activity in N cycling. 

LAP also shows that there are outliers skewing normality, and that Block and Treatment are importnat explanatory variables.

```{r}
x <- step1to3(data = enz[enz$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, 
                           data = enz[enz$Substrate %in% "LAP",], na.action = "na.fail"))
z

```


##### NAG  

N-acetyl-beta-glucosaminidase degrades chitin, which is a complex molecule but highly abundant in nature. 


```{r}
x <- step1to3(data = enz[enz$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz[enz$Substrate %in% "NAG",], 
                           na.action = "na.fail"))
z
```

##### PER1  

PER1 represents the net activity of phenol peroxidase, which degrades lignin. This is one of two substrates (PHENOX and PEROX) that are measured colorimetrically instead of fluorometrically, modifying the procedure of (Saiya-Cork et al., 2002). 

##### PHENOX  

PHENOX stands for phenol oxidase, which is another oxidative enzyme that degrades lignin. This substrate is also measured colorimetrically, similar to PEROX.

This is one dataset that actually could potentially be well illustrated with a GLM. The diagnostic plots show only a slight deviation from normality. The model selection shows that the log-transformed Gaussian is the best fit model, and that Block and GrazeTime are important explanatory variables. The GrazeTimes are not significant to each other, so there is potentially a block-GrazeTime interaction.

```{r}
x <- step1to3(data = enz[enz$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz[enz$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + GrazeTime + 1, 
                           data = enz[enz$Substrate %in% "PHENOX",], na.action = "na.fail"))
z
```

##### PHOS

Acid phosphatase, or PHOS, is the lone substrate that analyzes P-cycling, as acid phosphatase degrades phosphate esters. 

This data is widely distributed all over, which indiates that outliers may be randomly distributed. The QQplot shows a strange pattern, but the spread of residuals vs. explanatory variables is relatively uniform. The GLMs are throwing errors.

```{r}
x <- step1to3(data = enz[enz$Substrate %in% "PHOS",], variable.name = "Enzyme_nm_g_hr")
#y <- step4to5enz(data = enz[enz$Substrate %in% "PHOS",], variable.name = "Enzyme_nm_g_hr")
#y
# make sure to change "data" to the dataframe
#z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + GrazeTime + 1, 
  #                         data = enz[enz$Substrate %in% "PHENOX",], na.action = "na.fail"))
#z

```

#### Vegetation biomass

Vegetation biomass was quantified indirectly via rising plate pasture meter (RPM). The RPM has a flat metal disk that drops down onto the vegetation and is stopped by the density of the vegetation. The number that is recorded is the length that the metal plate drops. The RPM 'reading' is regressed to traditional clipped & dried vegetation biomass, to get an equation to convert RPM readings to vegetation structure. Vegetation structure is presented in units biomass per kg per plot (1/2 acre).

There are no potentially influential observations, and while there are a few outliers the data seems to generally fit a normal distribution well. The best fit model is the log-transformed Gaussian, which pulls Block and Treatment as the best explanatory variables. There is a strong block effect which interacts with Treatment.

I am guessing that Block 4 is the problem child here, as there is missing data in plot 12 for time 4WK, and plot 12 is always a problem because of the spatial distribution of irrigation water that pools in plot 12.

```{r}
veg$reading_rpm <- NULL
x <- step1to3(data = veg, variable.name = "biomass_kg_plot")
y <- step4to5(data = veg, variable.name = "biomass_kg_plot")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(biomass_kg_plot) ~ Block + Treatment + 1, 
                           data = veg, na.action = "na.fail"))
z
```

#### Forage Utilization

Forage utilization is calculated based on vegetation biomass. Forage utilization is the amount of forage the cows eat or trample within the grazing period. For the HI treatment, it is PRE-24H/PRE and since the LO treatment grazed for a longer period of time, the forage utilization is PRE-1WK/PRE. Both calculations compare the forage measured 24 hours after the grazing treatment concluded, compared to the baseline data. The plot shows a significant difference between the forage utilization of the two treatments, which is not what we wanted to see. Ideally the treatments would have the same forage utilziation, indiciating the same severity of grazing at different intensities.
The diagnostic plots for forage utilization will include a different linear regression model, since there is no GrazeTime factor, only one single forage utilization per treatment. Since the forage eaten is compared to the forage in the ungrazed plots, there is no forage utilization for the NO Treatment. There is n = 4 for each HI and LO treatment, one for each corresponding plot.


This data has to be analyzed by hand, since there is only one possible explanatory variable (Treatment). The boxplot shows one outlier, although potentially influential observations show no outliers. The QQplot is not normal. As there are not enough datapoints to really justify any other GLMs, only a log-transformed Gaussian distribution was ran. It shows that although the data is widely distributed, Treatment is not a significant factor.

This confirms that grazing was conducted uniformly across Treatments, which was the goal of the experimental design.
```{r}
# step 1: look for outliers with a boxplot
ggplot(data = for.ut18, aes(x = Treatment, y = forage_ut, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Forage Utilization 2018 Outliers") +
  labs(x = "Treatment", y = "Forage utilization")


# step 2: check for influential data points
summary(influence.measures(lm(forage_ut ~ Treatment, data = for.ut18)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(forage_ut ~ Treatment, data = for.ut18), add.smooth = FALSE, which = 1)
qqnorm(for.ut18$forage_ut)
qqline(for.ut18$forage_ut)

# fit a log-distributed Gaussian (normal) distribution 
(get.models(dredge(glm(log1p(forage_ut) ~ Treatment, data = for.ut18, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut18, na.action = "na.fail")))
qqline(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut18, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = log1p(forage_ut) ~ 1, data = for.ut18, na.action = "na.fail"))


```

#### Vegetation Recovery

Vegetation recovery is a calculation to measure how much the biomass changed per day of recovery following grazing. HI Grazing had 28 days of recovery while LO had 22 days of recovery, and the NO grazing control had 35 days which was all days of the grazing trial from PRE to 4WK. Similarly to Forage Utilization, there is one calculation for each plot. Therefore, this data also has to be analyzed by hand. 

The boxplot shows an outlier which is confirmed by the potentially influential observations function. The QQPlot is not normal but follows a sigmoid curve which could probably be rectified by a different transformation.
Similarly to forage utilization, only a Gaussian distribution is ran, but log-transformed is not possible since there are negative values. The best fit model shows that Treatment is not a good explanatory factor.
This suggests that Treatment does not impact the rate of vegetation recovery.

```{r}
# step 1: look for outliers with a boxplot
ggplot(data = veg.rec18, aes(x = Treatment, y = veg_rec, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Vegetation Recovery 2018 Outliers") +
  labs(x = "Treatment", y = "Forage utilization")


# step 2: check for influential data points
summary(influence.measures(lm(veg_rec ~ Treatment, data = veg.rec18)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(veg_rec ~ Treatment, data = veg.rec18), add.smooth = FALSE, which = 1)
qqnorm(veg.rec18$veg_rec)
qqline(veg.rec18$veg_rec)

# fit a Gaussian (normal) distribution 
(get.models(dredge(glm(veg_rec ~ Treatment, data = veg.rec18, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = veg_rec ~ 1, data = veg.rec18, na.action = "na.fail")))
qqline(resid(glm(formula = veg_rec ~ 1, data = veg.rec18, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = veg_rec ~ 1, data = veg.rec18, na.action = "na.fail"))



```


### 2017 Data 

The sampling design in 2017's grazing trial was such that there are 240 total samples, 5 from each plot of each GrazeTime. The methods and procedures for the analyses are identical to 2018 methods unless otherwise noted.

#### Gravimetric moisture  

Data exploration shows several outliers and influential measures, which indicate a high level of environmental variability. None of the three possible models improve the distribution of the QQPlot, and the log-transformed Gaussian has the lowest AIC. It pulls GrazeTime and Treatment as the best explanatory variables. 
This dataset is different than 2018 since none of the other biogeochemical factors are included. However, the AIC of the best fit model is 37 which is suitably low to fit well, even without the biogeochemical factors. 

```{r}
x <- step1to3(data = grav17, variable.name = "Gravmois")
y <- step4to5(data = grav17, variable.name = "Gravmois")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Gravmois) ~ GrazeTime + Treatment + 1, data = grav17, 
                           na.action = "na.fail")
)
z
```

#### pH  

pH was measured via electrode (Thomas 1996) in a 2:1 deonized water:soil solution. pH was only measured for times PRE and 4WK to ensure that grazing or seasonality did not have a significant difference on pH. The diagnostic plots show that there are multiple outliers that influence normality. Deleting outliers could sway this data to appropriately fit a linear regression. The outliers are abnormally low.
The best fit model is the Gamma distribution, which shows that Block and the PRE GrazeTime have significant effects. 

This ensures that pH is not affected by Treatment, and so we can assume changes in microbial community structure are not due to treatment-induced changes in pH.

```{r}

x <- step1to3(data = ph17, variable.name = "pH")
y <- step4to5(data = ph17, variable.name = "pH")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = pH ~ Block + GrazeTime + 1, family = Gamma(link = "log"), 
                          data = ph17, na.action = "na.fail")
)
z

```


#### Nitrate-N  

The problem with this dataset is that there were so many zeros that the QQplot turns asymptotic, and the spread of residuals is heteroscedastic. The multiple influential measures are almost all zeros. This problem is remedied in the 2018 data, since composited samples ensured there was less environmental noise and compensated for some spatial heterogeneity. 

This data is TOO zero-inflated to properly run the zero-inflated distributions function. The GaussianLog distribution has an AIC of 600, and the Gaussian distribution doesn't run at all. Therefore, we need another way to look at this data!

```{r}
x <- step1to3(data = cn17, variable.name = "NO3_mgkgdrysoil")
# the other functions don't run -- too zero-inflated 
```


#### Ammonium-N  

There are less outliers for 2017 Ammonium-N than 2017 Nitrate-N. However, the QQplot is still asymptotic and while the spread of residuals for explanatory variables is more even, the residuals vs. fitted plot shows problems. There are multiple outliers, the pattern of residuals vs. fitted values is not random, and the QQplot shows an upward curve pattern. However, the spread of residuals versus explanatory variables look relatively even.

The three model selections all show QQplots with different curves, which suggests that there may be a more appropriate transformation for this data than log tranformation. The Gamma and Gaussian distributions have AICs over 1000, which indicates that the model fits are extremely inappropriate for this data. The log-transformed Gaussian has an AIC of 123, which is not terrible but the QQPlot still suggests that normality is not met enough to run a Gaussian.
Anyways, the log-transformed Gaussian pulls Block, DON, GrazeTime, mineral N, and Nitrate as the best fitting explanatory variables. There is a strong block effect and the 4Wk GrazeTime is significantly lower than the other GrazeTimes. 

```{r}
x <- step1to3(data = cn17, variable.name = "NH4_mgkgdrysoil")
y <- step4to5(data = cn17, variable.name = "NH4_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(NH4_mgkgdrysoil) ~ Block + DON_mgkgdrysoil + 
                            GrazeTime + minN_mgkgdrysoil + NO3_mgkgdrysoil + 1, data = cn17, 
                          na.action = "na.fail")
)
z

```


#### Mineral N  

The diagnostic plots show that the dataset violates normality and heteroscedasity and is not fit for a linear regression model. This data resembles NH4 more than NO3, since NH4 is less zero-inflated it will be more influential on this measure.
Similarly to NH4, the QQplots all look awful and none of these models fit properly. However, the log-transformed Gaussian has the lowest AIC and it pulls Block, DON, GrazeTime, NH4, and NO3 as the best explanatory variables.
This follows similar trends as 2018 data, where biogeochemical factors are most influenced by each other. However, GrazeTime and Block seem to be integral drivers for the 2017 data.
The Blocks and GrazeTimes have wider confidence intervals, which suggests a wide spread of variable data. There is a strong block effect and the 4WK GrazeTime is significantly lower than the other GrazeTimes.
```{r}
x <- step1to3(data = cn17, variable.name = "minN_mgkgdrysoil")
y <- step4to5(data = cn17, variable.name = "minN_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(minN_mgkgdrysoil) ~ Block + DON_mgkgdrysoil + 
                            GrazeTime + NH4_mgkgdrysoil + NO3_mgkgdrysoil + 1, data = cn17, 
                          na.action = "na.fail")
)
z

```


#### NPOC  

NPOC shows a high amount of variability, but the data is close to fitting the assumptions of a linear regression and could probably be transformed more appropriately than applying a log transformation. The best fitting variables of the log-transformed Gaussian are Block, DON, GrazeTime, mineral N, NH4, and Treatment.
This is the first biogeochemical factor of both 2017 and 2018 data to suggest that Treatment is an influential driver. It seems that 

```{r}
x <- step1to3(data = cn17, variable.name = "NPOC_mgkgdrysoil")
y <- step4to5(data = cn17, variable.name = "NPOC_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(NPOC_mgkgdrysoil) ~ Block + DON_mgkgdrysoil + 
                            GrazeTime + minN_mgkgdrysoil + NH4_mgkgdrysoil + Treatment + 
                            1, data = cn17, na.action = "na.fail")
)
z

```



#### DON 

Dissolved organic nitrogen fits the assumptions of a linear regression well, except that the outliers skew normality. If outliers were removed it would likely fit the model assumptions. The QQplots actually look better than most of the other variables, and the best explanatory variables for the log-transformed Gaussian are Block, GrazeTime, mineral N, NH4, NPOC, and Treatment.
This is similar to the NPOC data, where the dredge() function pulled both GrazeTime and Treatment as explanatory variables. However, the effects are likely masked by the Block effect.
```{r}
x <- step1to3(data = cn17, variable.name = "DON_mgkgdrysoil")
y <- step4to5(data = cn17, variable.name = "DON_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(DON_mgkgdrysoil) ~ Block + GrazeTime + minN_mgkgdrysoil + 
                            NH4_mgkgdrysoil + NPOC_mgkgdrysoil + Treatment + 1, data = cn17, 
                          na.action = "na.fail")
)
z

```



#### MBC

Microbial biomass C was measured by fumigation-extraction (Horwath and Paul, 1994) with 0.5M K~2~SO~4~ and the combustion catalytic oxidation/NDIR method (Shimadzu TOC-VCPH with TNM-1, Shimadzu Corporation). A standard k~ec~ of 0.45 was used (Vance et al, 1985). MBC was calculated by subtracting NPOC of non-fumigated samples from NPOC of fumigated samples. Due to a laboratory error, there are 7 missing values for MBC and MBN. MBC was only measured for the 2017 grazing trial, since it was determined that the method was not sensitive enough for this project.
The dataset shows that although the data is not heterscedastic, it is zero-inflated and would fit another model more appropriately than a linear regression. The data is too zero-inflated to run a Gamma distribution, and the Gaussian log-transformed has an AIC of 854, which is considerably higher than it should be if the model fits appropriately.
However, the best explanatory variables are Block, DON, GrazeTime, MBN, and NPOC. This confirms that biogeochemical factors are influenced by each other, and GrazeTime likely explains trends as soil moisture fluctuates over the season.
```{r}
x <- step1to3(data = mbc17, variable.name = "MBC_mgkgdrysoil")
y <- step4to5zeroinfl(data = mbc17, variable.name = "MBC_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(MBC_mgkgdrysoil) ~ Block + DON_mgkgdrysoil + 
                            GrazeTime + MBN_mgkgdrysoil + NPOC_mgkgdrysoil + 1, data = mbc17, 
                          na.action = "na.fail")
)
z
```


#### MBN  

Microbial biomass N was only measured for 2017 samples. MBN is analyzed similarly to MBC, except with a standard k~ec~ of 0.54 (Brookes et al, 1985). In contrast to MBC, the MBN dataset is normally distributed and not zero-inflated, but the spread of fitted residuals is not ideal. The log-transformed Gaussian distribution fits considerably better than it fit the MBC data. The best fit variables are GrazeTime and MBC. Again, this illustrates that soil moisture throughout the 4 week sampling period likely has a larger influence on microbial variables than grazing.

```{r}
x <- step1to3(data = mbc17, variable.name = "MBN_mgkgdrysoil")
y <- step4to5zeroinfl(data = mbc17, variable.name = "MBN_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(MBN_mgkgdrysoil) ~ GrazeTime + MBC_mgkgdrysoil + 
                            1, data = mbc17, na.action = "na.fail")
)
z

```


#### Extracellular enzyme assays

Extracellular enzyme assays were conducted similarly as in 2018, following a modified procedure by (Bell et al, 2013). 

The boxplot and influential measures function for each of the 10 substrates shows similar trends as the 2018 dataset, except with considerably more varability. This is to be expected since these samples were not composited, and so there are more samples reflecting the true spatial variation and environmental noise than the composited samples. 

```{r}
# step 1: look for outliers with a boxplot
ggplot(data = enz17, aes(x = GrazeTime, y = Enzyme_nm_g_hr, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Enzymes 2017 Outliers") +
  labs(x = "GrazeTime", y = "Enzyme activity nm/g soil/hr") +
  facet_wrap(~ Substrate)

# step 2: look for influential data points
sub <- unique(enz17$Substrate)
infl <- list()
for(i in 1:length(sub)) {
  infl <- c(infl, list(influence.measures(
    lm(Enzyme_nm_g_hr ~ Treatment * GrazeTime, data = filter(enz17, Substrate == sub[i])))))
}
names(infl) <- sub
lapply(infl, summary)
```

##### AG

Violates normality and spread of fitted residuals.The best fitting model is a log-tranformed Gaussian, although QQPlots show that the models do not fit appropriately, and the lowest AIC value of 741 finds that there are no best explanatory variables. This illustrates that this data needs to be analyzed differently than in a GLM.

```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y
```

##### BG

This data looks surprisingly normal, and the log-transformed Gaussian shows that the best explanatory variables are Block and GrazeTime. However, the confidence intervals show the the data all deviates widely from the intercept, which may be where the significance is coming from.
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + GrazeTime + 1, 
                           data = enz17[enz17$Substrate %in% "BG",], na.action = "na.fail"))
z
```
##### BX

Violates normality because of high and low outliers. The fit of the three models are skewed by several outliers. This data shows a very similar pattern to BG. 
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + GrazeTime + 1, 
                           data = enz17[enz17$Substrate %in% "BX",], na.action = "na.fail"))
z

```
##### CBH 

This data is zero-inflated and multiple outliers pull the data so that no model fits appropriately enough to be analyzed further.
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y
```
##### LAP

A few more extreme outliers, and spread of residuals is different by treatment. Again, outliers pull the QQplots so that the normality doesn't fit well, but the AIC is low enough for log-transformed Gaussian that it can be analyzed further. There is a very strong block effect.
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, 
                           data = enz17[enz17$Substrate %in% "LAP",], na.action = "na.fail"))
z

```
##### NAG

This data is skewed with so many outliers and is zero-inflated to where none of the models run correctly.
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y
```


##### PER1


##### PEROX



##### PHENOX

Spread of fitted residuals is off, zero inflated plus high outliers. None of the models fit well enough to analyze further.

```{r}

x <- step1to3(data = enz17[enz17$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz(data = enz17[enz17$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y

```

##### PHOS

This data is so wonky that none of the models run accetably.
```{r}
x <- step1to3(data = enz17[enz17$Substrate %in% "PHOS",], variable.name = "Enzyme_nm_g_hr")
```


#### Microbial Efficiency  

Microbial efficiency is described as the enzymatic activity per unit of microbial biomass. This standardizes extracellular enzymatic activity to better describe the level of functional activity in the soil. Microbial efficiency is only calculated for 2017, since microbial biomass C was not analyzed in 2018. Microbial efficiency is calculated as:
  $$Eff = Enzyme Activity / Microbial Biomass$$  
  
The diagnostic plots for microbial efficiency will look similar to enzyme activity above.


```{r}
# step 1: look for outliers with a boxplot
ggplot(data = eff17, aes(x = GrazeTime, y = efficiency, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Microbial Efficiency 2017 Outliers") +
  labs(x = "GrazeTime", y = "Microbial Efficiency") +
  facet_wrap(~ Substrate)

# step 2: look for influential data points
sub <- unique(eff17$Substrate)
infl <- list()
for(i in 1:length(sub)) {
  infl <- c(infl, list(influence.measures(
    lm(efficiency ~ Treatment * GrazeTime, data = filter(eff17, Substrate == sub[i])))))
}
names(infl) <- sub
lapply(infl, summary)
```

##### AG

There are multiple influential measures, and the boxplot illustrates that there are several extremely high outliers. Thus, the QQplot is completely skewed and the residuals plots are all skewed by the high outliers. It's not surprising that the Gamma distribution doesn't run at all, the the Gaussian distributions have AICs that are too high.

```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "AG",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "AG",], variable.name = "efficiency")
y
```

##### BG

Similarly, BG is extremely influenced by high outliers, and neither model runs with an AIC under 1000.
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "BG",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "BG",], variable.name = "efficiency")
y
```
##### BX

While BX is also influenced by many high outliers, the log-transformed Gaussian has an AIC of 345. The best explanatory variables are most of the biogeochemical variables, GrazeTime, and Treatment. 
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "BX",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "BX",], variable.name = "efficiency")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(efficiency) ~ DON_mgkgdrysoil + GrazeTime + 
                             MBC_mgkgdrysoil + MBN_mgkgdrysoil + NPOC_mgkgdrysoil + Treatment + 
                             1, data = eff17[eff17$Substrate %in% "BX",], na.action = "na.fail"))
z

```
##### CBH 

Beyond the high outliers, CBH follows the similar trend as BX.
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "CBH",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "CBH",], variable.name = "efficiency")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(efficiency) ~ Block + DON_mgkgdrysoil + GrazeTime + 
                             MBC_mgkgdrysoil + minN_mgkgdrysoil + NPOC_mgkgdrysoil + Treatment + 
                             1, data = eff17[eff17$Substrate %in% "CBH",], na.action = "na.fail"))
z

```
##### LAP

While LAP is also influenced by many outliers, the QQplot shows a different distribution than the other substrates. None of the models run appropriately.
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "LAP",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "LAP",], variable.name = "efficiency")
y

```
##### NAG

The NAG substrate follows the same pattern as the other substrate.
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "NAG",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "NAG",], variable.name = "efficiency")
y
```


##### PER1


##### PEROX


##### PHENOX

This dataset is interesting because the data exploration plots show that the outliers may be distributed based on GrazeTime or Treatment, rather than randomly. This could be biologically important.
```{r}

x <- step1to3(data = eff17[eff17$Substrate %in% "PHENOX",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "PHENOX",], variable.name = "efficiency")
y

```

##### PHOS

Not surprisingly based on the 2018 and 2017 data, the PHOS efficiency has a very strange distribution.
```{r}
x <- step1to3(data = eff17[eff17$Substrate %in% "PHOS",], variable.name = "efficiency")
y <- step4to5enz_zeroinfl(data = eff17[eff17$Substrate %in% "PHOS",], variable.name = "efficiency")
y
```


#### Vegetation biomass

During 2017 data collection, not enough traditional clipped biomass was collected to have an acceptable regression between RPM readings and clipped biomass. The 2018 regression line is used to convert RPM readings to kg dry biomass per plot. 
This dataset has one potentially influential observation, and the selected model shows that Treatment is a significant factor. HI and LO are significant to NO. This suggests that HI recovered faster than LO and NO.
```{r}
# step 1: look for outliers with a boxplot
ggplot(data = veg.rec17, aes(x = Treatment, y = veg_rec, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Vegetation Recovery 2017 Outliers") +
  labs(x = "Treatment", y = "Vegetation Recovery")


# step 2: check for influential data points
summary(influence.measures(lm(veg_rec ~ Treatment, data = veg.rec17)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(veg_rec ~ Treatment, data = veg.rec18), add.smooth = FALSE, which = 1)
qqnorm(veg.rec17$veg_rec)
qqline(veg.rec17$veg_rec)

# fit a Gaussian (normal) distribution 
(get.models(dredge(glm(veg_rec ~ Treatment, data = veg.rec17, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = veg_rec ~ 1, data = veg.rec17, na.action = "na.fail")))
qqline(resid(glm(formula = veg_rec ~ 1, data = veg.rec17, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = veg_rec ~ Treatment + 1, data = veg.rec17, na.action = "na.fail"))
```

#### Forage Utilization

Similarly to the 2018 data, forage utilization is a calculation based on days of grazing. This also has to be done by hand, as there are not enough variables or observations for the functions. There is one potentially influential observation, but Treatment is not pulled as a significant factor.

```{r}
# step 1: look for outliers with a boxplot
ggplot(data = for.ut17, aes(x = Treatment, y = forage_ut, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Forage Utilization 2017 Outliers") +
  labs(x = "Treatment", y = "Forage utilization")


# step 2: check for influential data points
summary(influence.measures(lm(forage_ut ~ Treatment, data = for.ut17)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(forage_ut ~ Treatment, data = for.ut17), add.smooth = FALSE, which = 1)
qqnorm(for.ut17$forage_ut)
qqline(for.ut17$forage_ut)

# fit a log-distributed Gaussian (normal) distribution 
(get.models(dredge(glm(log1p(forage_ut) ~ Treatment, data = for.ut17, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut17, na.action = "na.fail")))
qqline(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut17, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = log1p(forage_ut) ~ 1, data = for.ut17, na.action = "na.fail"))

```


### 2018 and 2017 Combined Data

These analyses will be repeated on each inidividual univariate parameter, with combined 2018 and 2017 data. The 2017 data will be averaged by plot to match the n of the 2018 data.

```{r, echo = FALSE, include = FALSE}
## Combining 2017 and 2018 data


## cn and cn17
grav18 <- cn[ , c("GrazeTime", "Block", "Treatment", "grav_mois")]
cn$grav_mois <- NULL
cn17$mineralN_mgkgdrysoil <- cn17$minN_mgkgdrysoil
cn17$minN_mgkgdrysoil <- NULL
unique(names(cn)) %in% unique(names(cn17))

# average 2017 data by plot 

cn17.avg <- data.frame(summarise(group_by(.data = cn17, Block, Treatment, GrazeTime),
                                 NO3_mgkgdrysoil = mean(NO3_mgkgdrysoil, na.rm = TRUE),
                                 NH4_mgkgdrysoil = mean(NH4_mgkgdrysoil, na.rm = TRUE),
                                 NPOC_mgkgdrysoil = mean(NPOC_mgkgdrysoil, na.rm = TRUE),
                                 DON_mgkgdrysoil = mean(DON_mgkgdrysoil, na.rm = TRUE),
                                 mineralN_mgkgdrysoil = mean(mineralN_mgkgdrysoil, na.rm = TRUE)))
cn.all <- rbind(cn17.avg, cn)

## Gravimetric Moisture
grav17.avg <- data.frame(summarise(group_by(.data = grav17, Block, Treatment, GrazeTime),
                                   grav_mois = mean(Gravmois, na.rm = TRUE)))
grav.all <- rbind(grav18, grav17.avg)

## Enzymes
enz17.avg <- data.frame(summarise(group_by(.data = enz17, Block, Treatment,
                                           GrazeTime, Substrate),
                                  Enzyme_nm_g_hr = mean(Enzyme_nm_g_hr, na.rm = TRUE)))
enz.all <- rbind(enz17.avg, enz)

## Veg Biomass
veg$reading_rpm <- NULL
veg17.avg <- data.frame(summarise(group_by(.data = rpm17, Block, Treatment, GrazeTime),
                                  biomass_kg_plot = mean(biomass_kg_plot, na.rm = TRUE)))
veg.all <- rbind(veg, veg17.avg)

## Forage Utilization
for.ut.all <- rbind(for.ut17, for.ut18)

## Vegetation Recovery
veg.rec.all <- rbind(veg.rec17, veg.rec18)


```
#### Gravimetric Moisture

There are no potentially influential ovservations, and the QQplot shows that after transformation the data will likely appropriately fit a linear regression. The log-transformed Gaussian pulls GrazeTime as the best explanatory variable, confirming that gravimetric moisture is driven more by seasonality than treatment.
```{r}
x <- step1to3(data = grav.all, variable.name = "grav_mois")
y <- step4to5(data = grav.all, variable.name = "grav_mois")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(grav_mois) ~ GrazeTime + 1, data = grav.all, 
                          na.action = "na.fail")
           
)
z
```


#### Dissolved organic carbon

There are two major outliers that show on the boxplot and the influential measures function. A log transformation improves normality and heteroscedasticy, so with the outliers removed this dataset fits much better. The best explanatory varibales are DON, GrazeTime, and mineral N. This data follows the 2017 trend where seasonality influenced the biogeochemical factors. 
```{r}
x <- step1to3(data = cn.all, variable.name = "NPOC_mgkgdrysoil")
y <- step4to5(data = cn.all, variable.name = "NPOC_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(NPOC_mgkgdrysoil) ~ DON_mgkgdrysoil + GrazeTime + 
                            mineralN_mgkgdrysoil + 1, data = cn.all, na.action = "na.fail")
           
)
z

```


#### Dissolved organic nitrogen

There is a lot of variability in this dataset that creates violations of the linear regression model assumptions. High and low outliers skew normality and fitted residuals. The log-transformed Gaussian fits the QQplot better. The model significance plot shows that there are wide confidence intervals for the GrazeTimes and narrow CIs for mineral N and NPOC.
This confirms both years' trends that biogeochemical factors are largely influenced by each other.

```{r}
x <- step1to3(data = cn.all, variable.name = "DON_mgkgdrysoil")
y <- step4to5(data = cn.all, variable.name = "DON_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(DON_mgkgdrysoil) ~ GrazeTime + mineralN_mgkgdrysoil + 
                            NPOC_mgkgdrysoil + 1, data = cn.all, na.action = "na.fail")
           
)
z
```

#### Nitrate-N

This data is zero-inflated, but also has several high outliers creating heteroscedasity and non-normality. The Gamma distribution doesn't run correctly, and the log-transformed Gaussian doesn't fit a QQplot very well. However, it pulls DON, mineral N, and NH4 as explanatory variables.
```{r}
x <- step1to3(data = cn.all, variable.name = "NO3_mgkgdrysoil")
y <- step4to5zeroinfl(data = cn.all, variable.name = "NO3_mgkgdrysoil")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(NO3_mgkgdrysoil) ~ DON_mgkgdrysoil + mineralN_mgkgdrysoil + 
                            NH4_mgkgdrysoil + 1, data = cn.all, na.action = "na.fail")
           
)
z

```

#### Ammonium-N

There is one major outlier from the 2018 data that is extremely influential. With the outlier removed the data would likely fit the linear regression assumptions. However, the Gaussian and Gamma models don't run properly because the data is so skewed with the outlier. The log-tranformed Gaussian runs (by hand) and selects all of the biogeochemical variables as explanatory, as well as GrazeTime.
```{r}
x <- step1to3(data = cn.all, variable.name = "NH4_mgkgdrysoil")
# run by hand
modsGaussianLog <- get.models(dredge(
  glm(log1p(NH4_mgkgdrysoil) ~ .,
      data = cn.all, na.action = "na.fail")),
  subset = cumsum(weight) <= 0.95)[1]
modsGaussianLog
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(NH4_mgkgdrysoil) ~ DON_mgkgdrysoil + GrazeTime + 
                            mineralN_mgkgdrysoil + NO3_mgkgdrysoil + NPOC_mgkgdrysoil + 
                            1, data = cn.all, na.action = "na.fail")
           
)
z

```

#### Mineral-N

This data is more influenced by NH4 than NO3 and so the models also have to be run by hand. The biogeochemical factors and seasonality are important influencing factors.
```{r}
x <- step1to3(data = cn.all, variable.name = "NH4_mgkgdrysoil")
# run by hand
modsGaussianLog <- get.models(dredge(
  glm(log1p(mineralN_mgkgdrysoil) ~ .,
      data = cn.all, na.action = "na.fail")),
  subset = cumsum(weight) <= 0.95)[1]
modsGaussianLog
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(mineralN_mgkgdrysoil) ~ DON_mgkgdrysoil + 
                            GrazeTime + NH4_mgkgdrysoil + NO3_mgkgdrysoil + NPOC_mgkgdrysoil + 
                            1, data = cn.all, na.action = "na.fail")
           
)
z


```

#### Extracellular Enzyme Assays

The boxplot shows that there may be less outliers with the combined 2017 and 2018 data than with individual years. However, there are still outliers for every substrate 

```{r}
# step 1: look for outliers with a boxplot
ggplot(data = enz.all, aes(x = GrazeTime, y = Enzyme_nm_g_hr, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Enzymes 2017 Outliers") +
  labs(x = "GrazeTime", y = "Enzyme activity nm/g soil/hr") +
  facet_wrap(~ Substrate)

# step 2: look for influential data points
sub <- unique(enz.all$Substrate)
infl <- list()
for(i in 1:length(sub)) {
  infl <- c(infl, list(influence.measures(
    lm(Enzyme_nm_g_hr ~ Treatment * GrazeTime, data = filter(enz.all, Substrate == sub[i])))))
}
names(infl) <- sub
lapply(infl, summary)
```

##### AG

Interestingly, there are no potentially influential observations. That is surprising since enzyme data is known to be highly variable. There is a strong block effect that masks other potential drivers.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "AG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz.all[enz.all$Substrate %in% "AG",], 
                           na.action = "na.fail"))
z
```

##### BG

There are a few low outliers drawing everything off, but the data is not as variable as the years considered alone. The best explanatory variables are Block and Treatment.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "BG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, data = enz.all[enz.all$Substrate %in% "BG",], 
                           na.action = "na.fail"))
z
```
##### BX

There are a few high and low outliers, but is close to fitting assumptions. Similar to BG.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "BX",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, data = enz.all[enz.all$Substrate %in% "BX",], 
                           na.action = "na.fail"))
z

```
##### CBH 

There are a few high and low outliers, but overall the data looks fairly normal. However, log transforming does not suitably improve the QQPlot and the AIC is too high to be acceptable.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "CBH",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz.all[enz.all$Substrate %in% "CBH",], 
                           na.action = "na.fail"))
z

```
##### LAP

There are a few low outliers drawing off normality and the rest of the tranformations. There is a strong block effect.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "LAP",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, data = enz.all[enz.all$Substrate %in% "LAP",], 
                           na.action = "na.fail"))
z

```
##### NAG

The combined data looks more normal than the individual years. Although the QQPlot for Gaussian looks better than log-transformed Gaussian, log-transformed has the lower AIC. There is a Block and Treatment interaction.
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "NAG",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + Treatment + 1, data = enz.all[enz.all$Substrate %in% "NAG",], 
                           na.action = "na.fail"))
z

```


##### PER1

##### PEROX

##### PHENOX

The spread of residuals looks much better with combined data than individual years, but there is still a wide variability as shown by the boxplot. There is a strong block effect. 

```{r}

x <- step1to3(data = enz.all[enz.all$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "PHENOX",], variable.name = "Enzyme_nm_g_hr")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel = glm(formula = log1p(Enzyme_nm_g_hr) ~ Block + 1, data = enz.all[enz.all$Substrate %in% "PHENOX",], 
                           na.action = "na.fail"))
z

```

##### PHOS

QQplot still shows a weird shape, and the spread of fitted residuals shows a non-linear relationship. Interestingly, there are no potentially influential observations... maybe because the data is already so widely variable and random that outliers don't stand out?
```{r}
x <- step1to3(data = enz.all[enz.all$Substrate %in% "PHOS",], variable.name = "Enzyme_nm_g_hr")
y <- step4to5enz_zeroinfl(data = enz.all[enz.all$Substrate %in% "PHOS",], variable.name = "Enzyme_nm_g_hr")
y

```


#### Vegetation Biomass

The combined vegetation data is more variable than the individual years. Therefore, it will be more difficult to draw conclusions. The data are not normal following log transformation, but there are no outliers or influential observations. Treatment is pulled as the best explanatory variable.
```{r}
x <- step1to3(data = veg.all, variable.name = "biomass_kg_plot")
y <- step4to5(data = veg.all, variable.name = "biomass_kg_plot")
y
# make sure to change "data" to the dataframe
z <- step6(bestModel =glm(formula = log1p(biomass_kg_plot) ~ Treatment + 1, data = veg.all, 
                          na.action = "na.fail")
           
)
z

```

#### Forage Utilization

The 2017 data did not have to be averaged to combine it with the 2018 data, because there is one forage utilization calculation per plot for the grazed treatments only. There are no outliers or potentially influential observations, but the data aren't quite normal and fitted residuals are not randomly distributed. There seems to be no significant differences between Treatments.

```{r}
# step 1: look for outliers with a boxplot
ggplot(data = for.ut.all, aes(x = Treatment, y = forage_ut, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Forage Utilization 2017 & 2018 Outliers") +
  labs(x = "Treatment", y = "Forage utilization")


# step 2: check for influential data points
summary(influence.measures(lm(forage_ut ~ Treatment, data = for.ut.all)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(forage_ut ~ Treatment, data = for.ut.all), add.smooth = FALSE, which = 1)
qqnorm(for.ut.all$forage_ut)
qqline(for.ut.all$forage_ut)

# fit a log-distributed Gaussian (normal) distribution 
(get.models(dredge(glm(log1p(forage_ut) ~ Treatment, data = for.ut.all, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut.all, na.action = "na.fail")))
qqline(resid(glm(formula = log1p(forage_ut) ~ 1, data = for.ut.all, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = log1p(forage_ut) ~ 1, data = for.ut.all, na.action = "na.fail"))
```


#### Vegetation Recovery

Similarly to forage utilization, the 2017 vegetation recovery does not have to be averaged since there is one calculation per plot. There are two outliers, one of which is potentially influential, but the fitted residuals are not distributed randomly and the data are not normal. However, running a Gaussian distribution shows that there is no difference between Treatments. This is likely more influenced by the 2018 data.
```{r}
# step 1: look for outliers with a boxplot
ggplot(data = veg.rec.all, aes(x = Treatment, y = veg_rec, color = Treatment)) +
  geom_boxplot(outlier.colour = "black", outlier.size = 5, position = "dodge") +
  ggtitle("Vegetation Recovery 2017 & 2018 Outliers") +
  labs(x = "Treatment", y = "Forage utilization")


# step 2: check for influential data points
summary(influence.measures(lm(veg_rec ~ Treatment, data = veg.rec.all)))

# step 3: fit regression and look for violations of assumptions

# Standard model validation graphs: 1. residuals vs fitted values (test homogeneity), 2. QQplot  (test normality), 3. residuals vs each explanatory variable (test independence)
op <- par(mfrow = c(1,1), mar = c(5, 4, 1, 2))
plot(lm(veg_rec ~ Treatment, data = veg.rec.all), add.smooth = FALSE, which = 1)
qqnorm(veg.rec.all$veg_rec)
qqline(veg.rec.all$veg_rec)

# fit a Gaussian (normal) distribution 
(get.models(dredge(glm(veg_rec ~ Treatment, data = veg.rec.all, na.action = "na.fail")),
            subset = cumsum(weight) <= 0.95))[1]

# check the normality of the residuals with a QQplot
qqnorm(resid(glm(formula = veg_rec ~ 1, data = veg.rec.all, na.action = "na.fail")))
qqline(resid(glm(formula = veg_rec ~ 1, data = veg.rec.all, na.action = "na.fail")))

# summarize the best fit model
summary(glm(formula = veg_rec ~ 1, data = veg.rec.all, na.action = "na.fail"))


```

